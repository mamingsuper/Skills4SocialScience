---
layout: paper
title: "Can Large Language Models Transform Computational Social Science?"
description: "Evaluates zero-shot LLM performance across 25 CSS benchmarks, proposing a roadmap for integrating LLMs into the computational social science pipeline."
year: 2024
link: https://arxiv.org/abs/2305.03514
category: methodology
authors: "Caleb Ziems, William Held, Omar Shaikh, Jiaao Chen, Zhehao Zhang, Diyi Yang"
journal: "Computational Linguistics"
---
# Can Large Language Models Transform Computational Social Science?

Ziems et al. systematically evaluate 13 language models across 25 CSS benchmarks covering classification and generation tasks. Published in *Computational Linguistics* (2024).

**Key findings:**
- Zero-shot LLMs achieve fair agreement with human coders on classification tasks
- LLMs outperform crowdworkers on free-form coding / generation tasks
- Proposed best practices for prompting LLMs in CSS research pipelines
